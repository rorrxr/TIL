## 9장 웹 크롤러 설계

## 1. 웹 크롤러란?

웹 크롤러(Crawler)는 웹 페이지를 자동으로 탐색하고 정보를 수집하는 프로그램이다. 

검색 엔진, 데이터 마이닝, 웹 모니터링, 아카이빙 등 다양한 용도로 활용되며, "스파이더(Spider)" 또는 "봇(Bot)"이라고도 불린다.

### 활용 사례

- **검색 엔진 인덱싱**: 구글, 네이버와 같은 검색 엔진은 웹 크롤러를 통해 인덱스를 구축함 (예: Googlebot)
- **웹 아카이빙**: 국립 도서관, 정부기관이 보존용으로 사용 (예: 미국 국회 도서관)
- **웹 마이닝**: 금융, 리서치 기관이 웹에서 유의미한 데이터를 추출
- **웹 모니터링**: 저작권 침해, 브랜드 보호 등을 위한 자동화 탐지

## 2. 요구사항 분석 및 개략적 규모 추정

### 면접 질문 예시

- 크롤러의 목적: 검색 엔진 인덱싱
- 월간 수집량: 약 10억 페이지
- 콘텐츠 저장 여부: 5년간 보관 (30PB 예상)
- 중복 콘텐츠 처리: 무시 가능

### 규모 추정

- 평균 페이지 크기: 500KB
- QPS: 약 400 ~ 800
- 저장 용량: 약 500TB/월, 30PB/5년

## 3. 전체 시스템 구조 및 컴포넌트 설명

### 전체 구조 다이어그램

### 주요 컴포넌트

- **시작 URL 집합**: 크롤링의 출발점. 주제별, 지역별로 세분화 가능
- **미수집 URL 저장소**: FIFO 큐 형태로 미수집된 URL을 관리
- **HTML 다운로더**: 웹 페이지를 다운로드 (Robots.txt 고려)
- **도메인 이름 변환기**: URL -> IP 변환 (DNS 캐시 활용)
- **콘텐츠 파서**: HTML 검증 및 파싱 (비정상 입력 필터링)
- **중복 콘텐츠 필터**: 해시 기반으로 기존 콘텐츠 중복 여부 확인
- **콘텐츠 저장소**: 디스크 + 메모리 캐시 혼합형 저장소
- **URL 추출기**: HTML 내부 링크 파싱
- **URL 필터**: 확장자, 오류, 제외 목록 처리
- **URL 저장소**: 이미 방문한 URL 추적 (해시 테이블, 블룸 필터 사용)

## 4. 크롤링 작업 흐름

![image.png](attachment:acca430f-181d-4c8f-a45e-d0598c223a0d:image.png)

1. 시작 URL을 큐에 저장
2. 다운로더가 큐에서 URL을 꺼냄
3. IP 변환 및 HTML 다운로드
4. HTML 파싱 및 검증
5. 중복 검사 및 저장
6. URL 추출 및 필터링
7. 새 URL 저장 및 재순환

## 5. 상세 설계

### 5.1 BFS vs DFS

- 웹은 유향 그래프
- **DFS**: 깊이가 불확실하고 서버에 과부하 유발 가능 → 비선호
- **BFS**: FIFO 큐 기반, 더 예의 바른 크롤링 가능 → 일반적으로 사용

### 5.2 미수집 URL 저장소 최적화

- **예의**: 같은 호스트는 한 번에 하나의 요청만, 큐 분리 구조 적용
- **우선순위**: PageRank, 트래픽, 갱신 빈도 기반 큐 선택
- **신선도 유지**: 중요한 페이지는 더 자주 재수집
- **지속성 저장장치**: 메모리 + 디스크 하이브리드 설계

### 5.3 HTML 다운로더

- **Robots.txt 처리**: 크롤링 허용 범위 확인 후 저장
- **성능 최적화**:
    - 분산 크롤링 (서버 다중화)
    - DNS 캐싱
    - 지역성 활용 (지리적 분산 서버)
    - 타임아웃 설정

### 5.4 안정성과 확장성

- **안정 해시**: 서버 부하 분산
- **중간 상태 저장**: 장애 복구 대비
- **예외 처리 및 검증**: 무결성 유지
- **플러그인 구조**: PNG 다운로드, 저작권 모니터 등 확장 가능

### 5.5 문제 있는 콘텐츠 처리 전략

- **중복 콘텐츠**: 해시로 식별
- **거미 덫(무한 링크 루프)**: URL 길이 제한 및 수작업 차단
- **데이터 노이즈**: 광고, 스팸, JS 제거 전략 필요

## 6. 마무리 및 추가 논의 사항

웹 크롤러는 단순히 웹 페이지를 모으는 것 이상의 정교한 설계가 필요하다. 

확장성, 예의, 안정성, 유연성을 동시에 만족시켜야 하며, 다음 주제에 대해 추가 논의 가능하다.

- 동적 렌더링 처리
- 스팸 필터
- DB 샤딩/다중화
- 무상태 서버를 통한 수평적 확장
- 실시간 데이터 분석 및 로깅 전략