# 레이트 리미터(Rate Limiting) 설계 알고리즘 정리
대규모 트래픽을 처리하는 대부분의 시스템은 공통으로 **Rate Limiting(요청 제한)**을 사용합니다.

API 남용 방지, 과금 정책 관리, 트래픽 폭주 대응, 서비스 안정성 확보 등 **모든 백엔드 시스템에서 필수적인 요소**입니다.

하지만 레이트 리미터 구현을 떠올리면 많은 개발자들이 단순히 **카운터 증가(INCR)** 정도로 생각하곤 합니다.

그러나 실제 운영 환경에서는 **정확도, 자원 사용량, 동시성, 버스트 허용, 처리율 평탄화** 등 고려해야 할 요소가 훨씬 많습니다.

그래서 **레이트 리미트 알고리즘 대표 4가지 방식**을  
실제 운영 기준에서 비교하고, 어떤 상황에서 어떤 방식을 선택해야 하는지 정리해보겠습니다.

## 왜 레이트 리미팅이 필요한가?

시스템은 항상 **처리할 수 있는 한계**가 있습니다.  
갑작스런 트래픽 몰림(버스트)이 들어온다면 다음과 같은 문제가 발생합니다.

1. DB Connection Pool 고갈 → 전체 API 병목 발생
2. 외부 API 호출 제한 초과 → 4xx/5xx 연쇄 발생  
3. Redis/Cache 부하 폭증 → Latency 증가  
4. 장애 전파 → 전체 서비스 느려짐 또는 다운  

따라서 우리는 **유입되는 요청량을 제어**해 시스템을 보호해야 합니다.


# 레이트 리미트 알고리즘 4가지

아래 네 가지 방식이 가장 널리 쓰입니다.

1. **Fixed Window Counter (고정 윈도우)**
2. **Sliding Window (로그 기반 / 카운터 기반)**
3. **Token Bucket (토큰 버킷)**
4. **Leaky Bucket (리키 버킷)**

각 알고리즘은 목적과 동작 방식이 모두 다르기 때문에  
정답이 아니라 **상황에 맞는 선택**이 핵심입니다.

## 1️⃣ Fixed Window — 가장 간단하지만 가장 위험한 방식

### 개념
특정 **시계 시간 기준**으로 카운트만 세는 방식입니다.  
예: 1시간 동안 100회

- Redis 키: `rate:{user}:{YYYYMMDDHH}`
- 요청마다 `INCR`
- 100 초과면 차단

### 장점
- 구현이 매우 단순
- 메모리 사용 최소
- 카운터 1개면 끝

### 단점 (경계 문제)
예를 들어

- 13:59:59 → 100회  
- 14:00:01 → 100회  

단, 2초 동안 **200회가 허용**되는 문제가 있습니다.

### 결론
- 학습용, 로우 스케일에서는 가능  
- **실서비스에서는 거의 사용하지 않음**

## 2️⃣ Sliding Window — 정확하지만 두 가지 방식

슬라이딩 윈도우는 크게 **Log 기반**과 **Counter 기반**으로 나뉩니다.

### 1) Log 기반 (Windows Log / ZSET 기반)

- Redis ZSET에 **요청 timestamp를 모두 저장**
- 최근 1시간 이내 엔트리 개수를 기준으로 제한
- 정확도 최고

### 단점
요청 1건 = ZSET 1개 엔트리 →  
**대규모 트래픽에서 메모리 폭발**

### 2) Counter 기반 (Approx. Sliding Window)

- 시간을 작은 버킷(예: 1분)으로 나누고 각각 카운터 저장
- 최근 60개 버킷 합 ≤ limit
- Log 방식보다 메모리 고정

### 단점
버킷 경계에서 **근사 오차 발생**

### ✔ 결론
- 정확도 최우선 → **Log 방식**
- 메모리 절약 + 프로덕션 실용성 → **Counter 방식**
- 하지만 **버스트 제어는 여전히 한계**  
  → 이를 해결하는 것이 Token Bucket

## 3️⃣ Token Bucket — 가장 널리 쓰이는 실전형 알고리즘

AWS, Stripe 등 다수의 기업이 선택하는 레이트 리미터 알고리즘입니다.

### 개념
- 버킷에 토큰을 일정 속도로 채운다(+)
- 요청마다 토큰 cost만큼 사용(-)
- 토큰이 부족하면 요청 거절

즉, 토큰이 많으면 **버스트 허용**하고
장기적으로는 **평균 처리율 정확히 제어**합니다.

### 운영상의 강점
상태 값으로 `tokens`(남은 토큰)과 `ts`(마지막 보충 시각)을 가집니다.
- 버킷이 비면 자연스럽게 제한
- 남은 토큰으로 **재시도 가능 시간 계산 가능**
- Lua 스크립트로 **원자성 확보와 동시성 문제 해결** 

### 왜 Lazy Refill이 중요한가?
요청이 들어올 때만 토큰을 계산하는 방식(게으른 계산) 덕분에 별도 스케줄러 필요 없으며, CPU나 메모리 효율적이고, 간단하면서 정확도 유지할 수 있습니다.

### 결론
실서비스에서 가장 널리 쓰이며  
**MSA 환경에서 사실상 표준 레이트 리미터**를 사용합니다.

---

## 4️⃣ Leaky Bucket — Token Bucket과는 목적이 다르다

토큰 버킷이 **토큰이 채워지는 모델**이라면
리키 버킷은 **물이 흘러내리는 모델**입니다.

### 목적: 트래픽 평탄화(Smoothing)
- 갑작스러운 버스트를 억제하고  
- **일정 속도로만 요청이 흐르도록 조절**

### 적합한 상황
- 외부 API 호출량 평탄화  
- 메시지 처리 Worker 속도 보장  
- 외부 시스템 보호 목적

### Token Bucket과의 차이
- 토큰 버킷: `refill(+)`
- 리키 버킷: `leak(-)`

Lua 스크립트 구조는 거의 같고,  
“+”를 “−”로만 바꾸면 바로 전환할 수 있을 정도로 비슷합니다.

### 🎯 어떤 상황에서 어떤 알고리즘을 선택할까?

| 상황 | 추천 알고리즘 |
|------|---------------|
| 순간 버스트 허용 + 평균 처리율 제어 | **Token Bucket** |
| 외부 API 요청량 일정하게 유지 | **Leaky Bucket** |
| 정확한 “최근 1시간” 집계 필요 | **Sliding Window Log** |
| 리소스 절약 + 적당한 정확도 | **Sliding Window Counter** |


## 🏁 결론

레이트 리미팅은 단순히 “요청을 몇 개 제한하자”의 문제가 아닙니다.  
**시스템 전체 안정성, 성능, 사용자 경험, 비용 구조**까지 연결되는 중요한 설계 요소입니다.

특히 MSA 환경에서는  하나의 서비스 장애가 다른 서비스로 전파되는 것을 막기 위한 **필수 보호막**입니다.

다양한 알고리즘을 이해하면  트래픽 패턴에 따라 가장 적합한 방식을 선택할 수 있고  장애에 훨씬 강한 시스템을 만들 수 있습니다.
